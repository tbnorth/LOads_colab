{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LOads.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbnorth/LOads_colab/blob/master/LOads.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW-Jh5er5kCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62UIOjgh6s1C",
        "colab_type": "code",
        "outputId": "35550969-7aa5-4170-96b5-0498bad10d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")\n",
        "ROOT = Path(\"/content/gdrive/My Drive/Colab Notebooks\")\n",
        "BASE = ROOT.joinpath('LOads')\n",
        "BASE.mkdir(exist_ok=True)\n",
        "os.chdir(BASE)\n"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyaGn8iZEi3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import namedtuple\n",
        "from dateutil.parser import parse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wheVzmbh73ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# uploaded get_wqdata.py to Colab Notebooks folder, now add to import path\n",
        "import sys\n",
        "if BASE not in sys.path:\n",
        "    sys.path.append(str(BASE))\n",
        "from get_wqdata import GetWQData\n",
        "\n",
        "wq = GetWQData()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx15z3nOB5uJ",
        "colab_type": "text"
      },
      "source": [
        "Want to work out which CharacteristicName values to request.  The WQ portal web interface says they come [from here](http://iaspub.epa.gov/sor_internet/registry/substreg/home/overview/home.do) but that's hard to search, so request all obs. in our bounding box and search that list instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOM5hZUYCYxe",
        "colab_type": "code",
        "outputId": "fca9a55f-8a88-4972-b3fe-bb83766d1d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "collapsed": true
      },
      "source": [
        "query = dict(\n",
        "    _desc=\"All sample types\",\n",
        "    bBox=\"-80.0402,43.0646,-75.9697,44.355\",\n",
        "    siteType=[\"Aggregate surface-water-use\", \"Stream\"],\n",
        "    sampleMedia=[\"Water\", \"water\"],\n",
        "    # siteid=[\"USGS-04231600\"],\n",
        "    # startDateLo=\"01-01-2018\",\n",
        "    # startDateHi=\"02-01-2018\",\n",
        ")\n",
        "print(\"Reading data\")\n",
        "all_data = wq.get_data(query)  # gets path to .csv file\n",
        "d = pd.read_csv(all_data)  # , nrows=10)\n",
        "print(\"Data read\")\n",
        "print(d.columns)\n",
        "po4 = set(d[\"CharacteristicName\"])\n",
        "keep = set()\n",
        "for term in 'po4', 'phosphor', 'srp', 'phosphate', 'flow', 'guage', 'cfs':\n",
        "    for cname in po4:\n",
        "        if term in cname.lower():\n",
        "            keep.add(cname)\n",
        "print(sorted(keep))"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (9,10,11,13,19,20,22,24,25,33,35,39,41,42,44,55,56,57,61) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Data read\n",
            "Index(['OrganizationIdentifier', 'OrganizationFormalName',\n",
            "       'ActivityIdentifier', 'ActivityTypeCode', 'ActivityMediaName',\n",
            "       'ActivityMediaSubdivisionName', 'ActivityStartDate',\n",
            "       'ActivityStartTime/Time', 'ActivityStartTime/TimeZoneCode',\n",
            "       'ActivityEndDate', 'ActivityEndTime/Time',\n",
            "       'ActivityEndTime/TimeZoneCode',\n",
            "       'ActivityDepthHeightMeasure/MeasureValue',\n",
            "       'ActivityDepthHeightMeasure/MeasureUnitCode',\n",
            "       'ActivityDepthAltitudeReferencePointText',\n",
            "       'ActivityTopDepthHeightMeasure/MeasureValue',\n",
            "       'ActivityTopDepthHeightMeasure/MeasureUnitCode',\n",
            "       'ActivityBottomDepthHeightMeasure/MeasureValue',\n",
            "       'ActivityBottomDepthHeightMeasure/MeasureUnitCode', 'ProjectIdentifier',\n",
            "       'ActivityConductingOrganizationText', 'MonitoringLocationIdentifier',\n",
            "       'ActivityCommentText', 'SampleAquifer', 'HydrologicCondition',\n",
            "       'HydrologicEvent', 'SampleCollectionMethod/MethodIdentifier',\n",
            "       'SampleCollectionMethod/MethodIdentifierContext',\n",
            "       'SampleCollectionMethod/MethodName', 'SampleCollectionEquipmentName',\n",
            "       'ResultDetectionConditionText', 'CharacteristicName',\n",
            "       'ResultSampleFractionText', 'ResultMeasureValue',\n",
            "       'ResultMeasure/MeasureUnitCode', 'MeasureQualifierCode',\n",
            "       'ResultStatusIdentifier', 'StatisticalBaseCode', 'ResultValueTypeName',\n",
            "       'ResultWeightBasisText', 'ResultTimeBasisText',\n",
            "       'ResultTemperatureBasisText', 'ResultParticleSizeBasisText',\n",
            "       'PrecisionValue', 'ResultCommentText', 'USGSPCode',\n",
            "       'ResultDepthHeightMeasure/MeasureValue',\n",
            "       'ResultDepthHeightMeasure/MeasureUnitCode',\n",
            "       'ResultDepthAltitudeReferencePointText', 'SubjectTaxonomicName',\n",
            "       'SampleTissueAnatomyName', 'ResultAnalyticalMethod/MethodIdentifier',\n",
            "       'ResultAnalyticalMethod/MethodIdentifierContext',\n",
            "       'ResultAnalyticalMethod/MethodName', 'MethodDescriptionText',\n",
            "       'LaboratoryName', 'AnalysisStartDate', 'ResultLaboratoryCommentText',\n",
            "       'DetectionQuantitationLimitTypeName',\n",
            "       'DetectionQuantitationLimitMeasure/MeasureValue',\n",
            "       'DetectionQuantitationLimitMeasure/MeasureUnitCode',\n",
            "       'PreparationStartDate', 'ProviderName'],\n",
            "      dtype='object')\n",
            "['O-Ethyl O-methyl S-propyl phosphorothioate', 'O-Ethyl S-methyl S-propyl phosphorodithioate', 'O-Ethyl S-propyl phosphorothioate', 'Organic phosphorus', 'Orthophosphate', 'Orthophosphate as P', 'Phosphate-phosphorus', 'Phosphate-phosphorus as P', 'Phosphorus', 'Stream flow, instantaneous', 'Stream flow, mean. daily', 'Tributyl phosphate', 'Triphenyl phosphate', 'Tris(1,3-dichloro-2-propyl)phosphate', 'Tris(2-butoxyethyl) phosphate', 'Tris(2-chloroethyl) phosphate']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZxLuVimEBVF",
        "colab_type": "text"
      },
      "source": [
        "Now make a sensible list from the values we found."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVO8fq7dBn55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cache = {\n",
        "    'characteric_names': [\n",
        "        # 'O-Ethyl O-methyl S-propyl phosphorothioate',\n",
        "        # 'O-Ethyl S-methyl S-propyl phosphorodithioate',\n",
        "        # 'O-Ethyl S-propyl phosphorothioate',\n",
        "        # 'Organic phosphorus',\n",
        "        'Orthophosphate',\n",
        "        'Orthophosphate as P',\n",
        "        'Phosphate-phosphorus',\n",
        "        'Phosphate-phosphorus as P',\n",
        "        'Phosphorus',\n",
        "        'Stream flow, instantaneous',\n",
        "        'Stream flow, mean. daily',\n",
        "        # 'Tributyl phosphate',\n",
        "        # 'Triphenyl phosphate',\n",
        "        # 'Tris(1,3-dichloro-2-propyl)phosphate',\n",
        "        # 'Tris(2-butoxyethyl) phosphate',\n",
        "        # 'Tris(2-chloroethyl) phosphate',\n",
        "    ]\n",
        "}\n",
        "\n",
        "names = use_cache.get('characteric_names')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXAT9ESNFZXc",
        "colab_type": "text"
      },
      "source": [
        "Now grab all the data we're interested in"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLzhWPqJFQ7s",
        "colab_type": "code",
        "outputId": "b7a5f338-26f5-4479-f03f-25c48957a55d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "query = dict(\n",
        "    _desc=\"Target sample types\",\n",
        "    bBox=\"-80.0402,43.0646,-75.9697,44.355\",\n",
        "    siteType=[\"Aggregate surface-water-use\", \"Stream\"],\n",
        "    sampleMedia=[\"Water\", \"water\"],\n",
        "    characteristicName=names,\n",
        ")\n",
        "print(\"Reading data\")\n",
        "# first get the Site info. flavored response\n",
        "data = wq.get_data(query, type_='site')  # gets path to .csv file\n",
        "site = pd.read_csv(data)\n",
        "# print('\\n'.join(sorted(site.columns)))\n",
        "# then get the Result info.\n",
        "data = wq.get_data(query, type_='result')\n",
        "d = pd.read_csv(data, low_memory=False)\n",
        "d.columns = [i.replace('/', '_') for i in d.columns]\n",
        "# get rid of \"mg/l<space><space><space>\" units\n",
        "for col in ['ResultMeasure_MeasureUnitCode']:\n",
        "    d[col] = [str(i).strip() for i in d[col]]\n",
        "had = len(d)\n",
        "d = d.loc[d['ResultMeasure_MeasureUnitCode'] != 'nan', :]\n",
        "print(\"Lost %d for missing units\" % (had - len(d)))\n"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading data\n",
            "Lost 2251 for missing units\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqUj6aVFGVV2",
        "colab_type": "code",
        "outputId": "f7de5157-921c-47cd-c145-5e78d47bfd22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# find common columns\n",
        "common = set(site.columns).intersection(set(d.columns))\n",
        "print('\\n'.join(sorted(common)))\n",
        "# use this common column\n",
        "common = 'MonitoringLocationIdentifier'"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MonitoringLocationIdentifier\n",
            "OrganizationFormalName\n",
            "OrganizationIdentifier\n",
            "ProviderName\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlnI67nVGmFe",
        "colab_type": "code",
        "outputId": "4cae8994-1187-4c16-9939-dbef81c1f842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# create a list of unique sites\n",
        "locs = site.loc[:, [common, 'LatitudeMeasure', 'LongitudeMeasure']]\n",
        "locs.drop_duplicates(inplace=True)\n",
        "length = len(locs)\n",
        "length"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "230"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePo6lw_0HCh1",
        "colab_type": "code",
        "outputId": "66adb776-2cd1-45d4-f1c2-9196c37f6b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "# copy lat / lon to main data\n",
        "old_len = len(d)\n",
        "d = d.join(locs, rsuffix='CULL')\n",
        "assert len(d) == old_len\n",
        "d.drop(columns=[i for i in d.columns if 'CULL' in i], inplace=True)\n",
        "d.head()"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OrganizationIdentifier</th>\n",
              "      <th>OrganizationFormalName</th>\n",
              "      <th>ActivityIdentifier</th>\n",
              "      <th>ActivityTypeCode</th>\n",
              "      <th>ActivityMediaName</th>\n",
              "      <th>ActivityMediaSubdivisionName</th>\n",
              "      <th>ActivityStartDate</th>\n",
              "      <th>ActivityStartTime_Time</th>\n",
              "      <th>ActivityStartTime_TimeZoneCode</th>\n",
              "      <th>ActivityEndDate</th>\n",
              "      <th>ActivityEndTime_Time</th>\n",
              "      <th>ActivityEndTime_TimeZoneCode</th>\n",
              "      <th>ActivityDepthHeightMeasure_MeasureValue</th>\n",
              "      <th>ActivityDepthHeightMeasure_MeasureUnitCode</th>\n",
              "      <th>ActivityDepthAltitudeReferencePointText</th>\n",
              "      <th>ActivityTopDepthHeightMeasure_MeasureValue</th>\n",
              "      <th>ActivityTopDepthHeightMeasure_MeasureUnitCode</th>\n",
              "      <th>ActivityBottomDepthHeightMeasure_MeasureValue</th>\n",
              "      <th>ActivityBottomDepthHeightMeasure_MeasureUnitCode</th>\n",
              "      <th>ProjectIdentifier</th>\n",
              "      <th>ActivityConductingOrganizationText</th>\n",
              "      <th>MonitoringLocationIdentifier</th>\n",
              "      <th>ActivityCommentText</th>\n",
              "      <th>SampleAquifer</th>\n",
              "      <th>HydrologicCondition</th>\n",
              "      <th>HydrologicEvent</th>\n",
              "      <th>SampleCollectionMethod_MethodIdentifier</th>\n",
              "      <th>SampleCollectionMethod_MethodIdentifierContext</th>\n",
              "      <th>SampleCollectionMethod_MethodName</th>\n",
              "      <th>SampleCollectionEquipmentName</th>\n",
              "      <th>ResultDetectionConditionText</th>\n",
              "      <th>CharacteristicName</th>\n",
              "      <th>ResultSampleFractionText</th>\n",
              "      <th>ResultMeasureValue</th>\n",
              "      <th>ResultMeasure_MeasureUnitCode</th>\n",
              "      <th>MeasureQualifierCode</th>\n",
              "      <th>ResultStatusIdentifier</th>\n",
              "      <th>StatisticalBaseCode</th>\n",
              "      <th>ResultValueTypeName</th>\n",
              "      <th>ResultWeightBasisText</th>\n",
              "      <th>ResultTimeBasisText</th>\n",
              "      <th>ResultTemperatureBasisText</th>\n",
              "      <th>ResultParticleSizeBasisText</th>\n",
              "      <th>PrecisionValue</th>\n",
              "      <th>ResultCommentText</th>\n",
              "      <th>USGSPCode</th>\n",
              "      <th>ResultDepthHeightMeasure_MeasureValue</th>\n",
              "      <th>ResultDepthHeightMeasure_MeasureUnitCode</th>\n",
              "      <th>ResultDepthAltitudeReferencePointText</th>\n",
              "      <th>SubjectTaxonomicName</th>\n",
              "      <th>SampleTissueAnatomyName</th>\n",
              "      <th>ResultAnalyticalMethod_MethodIdentifier</th>\n",
              "      <th>ResultAnalyticalMethod_MethodIdentifierContext</th>\n",
              "      <th>ResultAnalyticalMethod_MethodName</th>\n",
              "      <th>MethodDescriptionText</th>\n",
              "      <th>LaboratoryName</th>\n",
              "      <th>AnalysisStartDate</th>\n",
              "      <th>ResultLaboratoryCommentText</th>\n",
              "      <th>DetectionQuantitationLimitTypeName</th>\n",
              "      <th>DetectionQuantitationLimitMeasure_MeasureValue</th>\n",
              "      <th>DetectionQuantitationLimitMeasure_MeasureUnitCode</th>\n",
              "      <th>PreparationStartDate</th>\n",
              "      <th>ProviderName</th>\n",
              "      <th>LatitudeMeasure</th>\n",
              "      <th>LongitudeMeasure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>USGS-NY</td>\n",
              "      <td>USGS New York Water Science Center</td>\n",
              "      <td>nwisny.01.96300165</td>\n",
              "      <td>Sample-Routine</td>\n",
              "      <td>Water</td>\n",
              "      <td>Surface Water</td>\n",
              "      <td>1963-05-08</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USGS-04217500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Not determined</td>\n",
              "      <td>Routine sample</td>\n",
              "      <td>USGS</td>\n",
              "      <td>USGS</td>\n",
              "      <td>USGS</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Stream flow, mean. daily</td>\n",
              "      <td>NaN</td>\n",
              "      <td>99.0</td>\n",
              "      <td>ft3/s</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Historical</td>\n",
              "      <td>Mean</td>\n",
              "      <td>Actual</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1 Day</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>60.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NWIS</td>\n",
              "      <td>43.091111</td>\n",
              "      <td>-78.453889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>USGS-NY</td>\n",
              "      <td>USGS New York Water Science Center</td>\n",
              "      <td>nwisny.01.96300166</td>\n",
              "      <td>Sample-Routine</td>\n",
              "      <td>Water</td>\n",
              "      <td>Surface Water</td>\n",
              "      <td>1963-07-02</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USGS-04217500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Not determined</td>\n",
              "      <td>Routine sample</td>\n",
              "      <td>USGS</td>\n",
              "      <td>USGS</td>\n",
              "      <td>USGS</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Stream flow, mean. daily</td>\n",
              "      <td>NaN</td>\n",
              "      <td>35.0</td>\n",
              "      <td>ft3/s</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Historical</td>\n",
              "      <td>Mean</td>\n",
              "      <td>Actual</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1 Day</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>60.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NWIS</td>\n",
              "      <td>43.093056</td>\n",
              "      <td>-78.636111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>USGS-NY</td>\n",
              "      <td>USGS New York Water Science Center</td>\n",
              "      <td>nwisny.01.96400190</td>\n",
              "      <td>Sample-Routine</td>\n",
              "      <td>Water</td>\n",
              "      <td>Surface Water</td>\n",
              "      <td>1964-03-05</td>\n",
              "      <td>04:50:00</td>\n",
              "      <td>EST</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USGS-04217500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Not determined</td>\n",
              "      <td>Routine sample</td>\n",
              "      <td>USGS</td>\n",
              "      <td>USGS</td>\n",
              "      <td>USGS</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Stream flow, mean. daily</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2200.0</td>\n",
              "      <td>ft3/s</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Historical</td>\n",
              "      <td>Mean</td>\n",
              "      <td>Actual</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1 Day</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>60.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NWIS</td>\n",
              "      <td>43.086169</td>\n",
              "      <td>-78.696976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>USGS-NY</td>\n",
              "      <td>USGS New York Water Science Center</td>\n",
              "      <td>nwisny.01.96400191</td>\n",
              "      <td>Sample-Routine</td>\n",
              "      <td>Water</td>\n",
              "      <td>Surface Water</td>\n",
              "      <td>1964-04-16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USGS-04217500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Not determined</td>\n",
              "      <td>Routine sample</td>\n",
              "      <td>USGS</td>\n",
              "      <td>USGS</td>\n",
              "      <td>USGS</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Stream flow, mean. daily</td>\n",
              "      <td>NaN</td>\n",
              "      <td>261.0</td>\n",
              "      <td>ft3/s</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Historical</td>\n",
              "      <td>Mean</td>\n",
              "      <td>Actual</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1 Day</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>60.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NWIS</td>\n",
              "      <td>43.120336</td>\n",
              "      <td>-78.518081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>USGS-NY</td>\n",
              "      <td>USGS New York Water Science Center</td>\n",
              "      <td>nwisny.01.96300169</td>\n",
              "      <td>Sample-Routine</td>\n",
              "      <td>Water</td>\n",
              "      <td>Surface Water</td>\n",
              "      <td>1963-05-08</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USGS-04218000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Not determined</td>\n",
              "      <td>Routine sample</td>\n",
              "      <td>USGS</td>\n",
              "      <td>USGS</td>\n",
              "      <td>USGS</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Stream flow, mean. daily</td>\n",
              "      <td>NaN</td>\n",
              "      <td>165.0</td>\n",
              "      <td>ft3/s</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Historical</td>\n",
              "      <td>Mean</td>\n",
              "      <td>Actual</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1 Day</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>60.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NWIS</td>\n",
              "      <td>43.086169</td>\n",
              "      <td>-78.727532</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  OrganizationIdentifier  ... LongitudeMeasure\n",
              "0                USGS-NY  ...       -78.453889\n",
              "1                USGS-NY  ...       -78.636111\n",
              "2                USGS-NY  ...       -78.696976\n",
              "3                USGS-NY  ...       -78.518081\n",
              "4                USGS-NY  ...       -78.727532\n",
              "\n",
              "[5 rows x 65 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7n1oI1XI178",
        "colab_type": "text"
      },
      "source": [
        "Data has different `MonitoringLocationIdentifier`s for the same coords."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkFwnJS9IDWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate a location based site field\n",
        "dd = d.copy(deep=False)\n",
        "# round lat lon to snap nearby points together\n",
        "dd['_lat'] = np.round(dd['LatitudeMeasure'], 3)\n",
        "dd['_lon'] = np.round(dd['LongitudeMeasure'], 3)\n",
        "dd.set_index(['_lat', '_lon'], inplace=True)\n",
        "# use mean of snapped points, same as original for\n",
        "# points that were all together to start with\n",
        "mean = dd.groupby(by=['_lat', '_lon']).mean()\n",
        "dd = dd.join(mean, on=['_lat', '_lon'], rsuffix=\"MEAN\")\n",
        "d['lat'] = dd['LatitudeMeasureMEAN'].values\n",
        "d['lon'] = dd['LongitudeMeasureMEAN'].values\n",
        "d['site'] = np.round(d['lat'],4).astype(str) + np.round(d['lon'], 4).astype(str)\n",
        "assert len(d) == old_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pXzMa7wJ-3H",
        "colab_type": "text"
      },
      "source": [
        "Now copy site info. into locs table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgY12QBVKEtF",
        "colab_type": "code",
        "outputId": "e9bb08ea-02b8-4ad3-95a4-37c4de6f2155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "d.set_index(['LatitudeMeasure', 'LongitudeMeasure'], inplace=True, drop=False)\n",
        "locs = locs.join(d, on=['LatitudeMeasure', 'LongitudeMeasure'], rsuffix='CULL')\n",
        "for col in [i for i in locs.columns if 'CULL' in i]:\n",
        "    locs.drop(columns=col, inplace=True)\n",
        "locs.drop_duplicates(inplace=True, subset=['site', 'MonitoringLocationIdentifier'])\n",
        "locs.to_csv(\"locs.csv\", index=False)\n",
        "offset = max((locs['lat']-locs['LatitudeMeasure']).abs())\n",
        "assert offset < 0.001, offset\n",
        "assert len(locs) == length, (length, len(locs))\n",
        "locs.to_csv(\"locs.csv\")\n",
        "offset"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00013884999999902448"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1stEddL4jqzb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ec774e62-8807-48ec-f1ac-0f5ab57cb6e0"
      },
      "source": [
        "print(\"%d locations\" % len(locs))\n",
        "distinct = locs.set_index([\"LatitudeMeasure\", \"LongitudeMeasure\"]).index\n",
        "print(\"%d distinct\" % len(distinct.unique()))\n",
        "distinct = locs.set_index([\"lat\", \"lon\"]).index\n",
        "print(\"%d really distinct\" % len(distinct.unique()))"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "230 locations\n",
            "192 distinct\n",
            "187 really distinct\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVH5IJXWkhUN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "fea2cdcc-f3ae-4022-ef9d-162e0aa7fae2"
      },
      "source": [
        "# tabulate units used for results\n",
        "d['ResultSampleFractionText'] = [\n",
        "    i if i != 'nan' else 'NA'\n",
        "    for i in d['ResultSampleFractionText'].astype(str)\n",
        "]\n",
        "\n",
        "res_types = (\n",
        "    d.groupby(\n",
        "        [\n",
        "            'CharacteristicName',\n",
        "            'ResultMeasure_MeasureUnitCode',\n",
        "            'ResultSampleFractionText',\n",
        "        ]\n",
        "    )\n",
        "    .count()\n",
        "    .iloc[:, 0]\n",
        ")\n",
        "print(res_types)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CharacteristicName          ResultMeasure_MeasureUnitCode  ResultSampleFractionText\n",
            "Orthophosphate              mg/l                           Dissolved                     181\n",
            "                                                           NA                             36\n",
            "                                                           Total                         119\n",
            "                            mg/l as P                      Dissolved                   18392\n",
            "                                                           Total                         380\n",
            "                            mg/l asPO4                     Dissolved                   18393\n",
            "Orthophosphate as P         mg/l                           Dissolved                     122\n",
            "                                                           Total                           1\n",
            "Phosphate-phosphorus        mg/l                           Total                         417\n",
            "Phosphate-phosphorus as P   mg/l                           NA                            147\n",
            "                                                           Total                         211\n",
            "Phosphorus                  mg/kg as P                     Bed Sediment                    8\n",
            "                            mg/l                           Dissolved                       1\n",
            "                                                           NA                             40\n",
            "                                                           Total                         318\n",
            "                            mg/l PO4                       Total                         736\n",
            "                            mg/l as P                      Dissolved                    1171\n",
            "                                                           Total                       19901\n",
            "                            ug/l                           NA                              3\n",
            "Stream flow, instantaneous  ft3/s                          NA                           3244\n",
            "                            m3/sec                         NA                           3244\n",
            "Stream flow, mean. daily    ft3/s                          NA                          15321\n",
            "Name: OrganizationIdentifier, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvDaZ5-pkvVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duration = wq.db.get('duration', [])  # cache expensive calc. in wq.db\n",
        "if not duration:\n",
        "    for row in d.itertuples():\n",
        "        try:\n",
        "            t0 = parse(\n",
        "                \"%s %s\"\n",
        "                % (row.ActivityStartDate, row.ActivityStartTime_Time)\n",
        "            )\n",
        "            t1 = parse(\n",
        "                \"%s %s\" % (row.ActivityEndDate, row.ActivityEndTime_Time)\n",
        "            )\n",
        "            duration.append((t1 - t0).seconds)\n",
        "        except ValueError:\n",
        "            duration.append(0)\n",
        "    wq.db['duration'] = duration\n",
        "d['duration'] = duration"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIbZBmsClx1c",
        "colab_type": "text"
      },
      "source": [
        "Create an ID field for each sampling event"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYZXRm5jlp-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d['sampling'] = (\n",
        "    d['ActivityStartTime_Time'].astype(str)\n",
        "    + d['ActivityEndTime_Time'].astype(str)\n",
        "    + ' '\n",
        "    + d['ActivityStartDate'].astype(str)\n",
        "    + ' '\n",
        "    + d['ActivityEndDate'].astype(str)\n",
        "    + ' '\n",
        "    + d['LatitudeMeasure'].astype(str)\n",
        "    + ' '\n",
        "    + d['LongitudeMeasure'].astype(str)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wv941RAmIeb",
        "colab_type": "text"
      },
      "source": [
        "## Save output data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLjS3EC3mMfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d.to_csv('data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PqLby2umSla",
        "colab_type": "text"
      },
      "source": [
        "Now we want to match P conc. data and flow data for each sampling event\n",
        "\n",
        "(start to refer to `d` as `data` from here on)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHhBDk2nmh0q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ae6829c-64a7-4f49-ec87-87b2a889c476"
      },
      "source": [
        "data = pd.read_csv(\"data.csv\", low_memory=False)\n",
        "pdata = data.loc[:, ['sampling', 'site']]\n",
        "pdata.drop_duplicates(subset=['sampling'], inplace=True)\n",
        "pdata_len = len(pdata)\n",
        "print(\"%d into %d\" % (len(data), pdata_len))\n",
        "cname = 'CharacteristicName'\n",
        "cunit = 'ResultMeasure_MeasureUnitCode'\n",
        "vname = 'ResultMeasureValue'\n",
        "TP = namedtuple(\"ToProcess\", \"to cname unit trans\")\n",
        "po4_to_p = (30.97 + 4 * 16) / 30.97\n",
        "to_process = [\n",
        "    TP('flow', 'Stream flow, instantaneous', 'ft3/s', None),\n",
        "    TP(\n",
        "        'flow',\n",
        "        'Stream flow, instantaneous',\n",
        "        'm3/sec',\n",
        "        lambda x: x * 35.3147,\n",
        "    ),\n",
        "    TP('flow', 'Stream flow, mean. daily', 'ft3/s', None),\n",
        "    TP('conc', 'Phosphorus', 'mg/l as P', None),\n",
        "    TP('conc', 'Phosphorus', 'mg/l', None),\n",
        "    TP('conc', 'Phosphorus', 'ug/l', lambda x: 1000 * x),\n",
        "    TP('conc', 'Phosphorus', 'mg/l PO4', lambda x: x / po4_to_p),\n",
        "    TP('conc', 'Phosphate-phosphorus as P', 'mg/l', None),\n",
        "    TP('conc', 'Phosphate-phosphorus', 'mg/l', None),\n",
        "    TP('conc', 'Orthophosphate as P', 'mg/l', None),\n",
        "    TP('conc', 'Orthophosphate', 'mg/l as P', None),\n",
        "    TP('conc', 'Orthophosphate', 'mg/l asPO4', lambda x: x / po4_to_p),\n",
        "    TP('conc', 'Orthophosphate', 'mg/l', lambda x: x / po4_to_p),\n",
        "    # exclude as it's in bed sediment\n",
        "    # TP('conc', 'Phosphorus', 'mg/kg as P', None),\n",
        "]"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82386 into 21877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPGAFGYinYDL",
        "colab_type": "text"
      },
      "source": [
        "We're merging 82386 observations into 21877 flow + conc. records.  In a perfect world we'd have one flow and one conc. record for each sampling, but we have both redundant and mismatched (flow without conc. and visa versa) records, roughly 4:1 instead of 2:1.\n",
        "\n",
        "`to_process` is an **ordered** list of items where each item reocords the field we're trying to fill (`to`), the `CharacteristicName` (`cname`) of our prefered source field, our prefered `unit`, and any conversion (`trans`) necessary to use this source field / unit combination.\n",
        "\n",
        "Now we're going to fill the `to` fields (`flow`, `conc`) with the values selected using the list items, filling as many records with the first set of selected data, and only filling missing records with the next (less desireable) list item."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eb6WyR0ozty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "079dfa9c-6efb-4fa8-ccd1-894230cc00e6"
      },
      "source": [
        "selected = 0\n",
        "data.set_index('sampling', drop=False, inplace=True)\n",
        "pdata.set_index('sampling', drop=False, inplace=True)\n",
        "for tp_i, tp in enumerate(to_process):\n",
        "    select = np.logical_and(\n",
        "        data[cname] == tp.cname, data[cunit] == tp.unit\n",
        "    )\n",
        "    selected += sum(select)\n",
        "    print(\n",
        "        \"%d Selected %d %s %s (%d)\"\n",
        "        % (\n",
        "            tp_i, sum(select),\n",
        "            tp.cname,\n",
        "            tp.unit,\n",
        "            len(data['sampling'][select].unique()),\n",
        "        )\n",
        "    )\n",
        "    mean = data.loc[select, :]\n",
        "    mean = mean.groupby(level=0).mean()\n",
        "    pdata = pdata.join(mean.loc[:, vname])\n",
        "    assert len(pdata) == pdata_len, (pdata_len, len(pdata))\n",
        "    if tp.trans is not None:\n",
        "        pdata[vname] = pdata[vname].map(tp.trans)\n",
        "\n",
        "    def missing(x, f):\n",
        "        if f not in x.columns:\n",
        "            return np.ones(len(x)).astype(bool)\n",
        "        x = x[f].astype(str)\n",
        "        ans = np.logical_or(np.equal(x, 'None'), np.equal(x, ''))\n",
        "        ans = np.logical_or(ans, np.equal(x, 'nan'))\n",
        "        ans = np.logical_or(ans, np.equal(x, 'NaN'))\n",
        "        return ans\n",
        "\n",
        "    missing0 = missing(pdata, tp.to)\n",
        "    if tp.to not in pdata.columns:\n",
        "        pdata.rename(columns={vname: tp.to}, inplace=True)\n",
        "    else:\n",
        "        # print(len(missing), sum(missing), missing.shape)\n",
        "        #X pdata[tp.to][missing0] = pdata[vname][missing0]\n",
        "        pdata.loc[missing0, tp.to] = pdata[vname][missing0]\n",
        "        pdata.drop(columns=vname, inplace=True)\n",
        "    missing1 = missing(pdata, tp.to)\n",
        "    print(\n",
        "        \"%d, Needed %d, used %d, still need %d\"\n",
        "        % (tp_i, sum(missing0), sum(missing0) - sum(missing1), sum(missing1))\n",
        "    )\n",
        "    assert len(pdata) == pdata_len, (pdata_len, len(pdata))\n",
        "print(\"Selected %s total\" % selected)\n",
        "pdata = pdata[~np.isnan(pdata['conc'])]\n",
        "pdata = pdata[~np.isnan(pdata['flow'])]\n",
        "print(\"Lost %d to blank data\" % (pdata_len-len(pdata)))\n",
        "pdata.to_csv(\"pdata.csv\")"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Selected 3244 Stream flow, instantaneous ft3/s (3210)\n",
            "0, Needed 21877, used 3210, still need 18667\n",
            "1 Selected 3244 Stream flow, instantaneous m3/sec (3210)\n",
            "1, Needed 18667, used 32, still need 18635\n",
            "2 Selected 15321 Stream flow, mean. daily ft3/s (15191)\n",
            "2, Needed 18635, used 15082, still need 3553\n",
            "3 Selected 21072 Phosphorus mg/l as P (19628)\n",
            "3, Needed 21877, used 19628, still need 2249\n",
            "4 Selected 359 Phosphorus mg/l (299)\n",
            "4, Needed 2249, used 292, still need 1957\n",
            "5 Selected 3 Phosphorus ug/l (3)\n",
            "5, Needed 1957, used 3, still need 1954\n",
            "6 Selected 736 Phosphorus mg/l PO4 (680)\n",
            "6, Needed 1954, used 110, still need 1844\n",
            "7 Selected 358 Phosphate-phosphorus as P mg/l (335)\n",
            "7, Needed 1844, used 334, still need 1510\n",
            "8 Selected 417 Phosphate-phosphorus mg/l (404)\n",
            "8, Needed 1510, used 7, still need 1503\n",
            "9 Selected 123 Orthophosphate as P mg/l (115)\n",
            "9, Needed 1503, used 0, still need 1503\n",
            "10 Selected 18772 Orthophosphate mg/l as P (18192)\n",
            "10, Needed 1503, used 374, still need 1129\n",
            "11 Selected 18393 Orthophosphate mg/l asPO4 (18143)\n",
            "11, Needed 1129, used 23, still need 1106\n",
            "12 Selected 336 Orthophosphate mg/l (280)\n",
            "12, Needed 1106, used 1, still need 1105\n",
            "Selected 82378 total\n",
            "Lost 4658 to blank data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_kz258y4_mY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61494197-26f7-4743-e248-39f8ced37508"
      },
      "source": [
        "# update locs with the number of obs. for each site\n",
        "count = pdata.groupby(by=['site']).count().iloc[:, 0]\n",
        "count.columns = ['count']\n",
        "locs = locs.join(count, on='site')\n",
        "locs.to_csv(\"locs.csv\")"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sampling</th>\n",
              "      <th>site</th>\n",
              "      <th>flow</th>\n",
              "      <th>conc</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sampling</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>08:00:00nan 1987-04-15 nan 43.0745076 -77.436104</th>\n",
              "      <td>08:00:00nan 1987-04-15 nan 43.0745076 -77.436104</td>\n",
              "      <td>43.0745-77.4361</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0.019892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>08:00:00nan 1987-04-28 nan 43.090618400000004 -77.53083079999999</th>\n",
              "      <td>08:00:00nan 1987-04-28 nan 43.090618400000004 ...</td>\n",
              "      <td>43.0906-77.5308</td>\n",
              "      <td>320.0</td>\n",
              "      <td>0.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12:00:00nan 1988-03-22 nan 43.135062899999994 -77.4986078</th>\n",
              "      <td>12:00:00nan 1988-03-22 nan 43.135062899999994 ...</td>\n",
              "      <td>43.1351-77.4986</td>\n",
              "      <td>320.0</td>\n",
              "      <td>0.030001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12:45:00nan 1988-04-06 nan 43.147285 -77.5124973</th>\n",
              "      <td>12:45:00nan 1988-04-06 nan 43.147285 -77.5124973</td>\n",
              "      <td>43.1473-77.5125</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11:45:00nan 1988-05-03 nan 43.1761737 -77.52666479999999</th>\n",
              "      <td>11:45:00nan 1988-05-03 nan 43.1761737 -77.5266...</td>\n",
              "      <td>43.1762-77.5267</td>\n",
              "      <td>640.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14:30:00nan 2015-04-08 nan nan nan</th>\n",
              "      <td>14:30:00nan 2015-04-08 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>239000.0</td>\n",
              "      <td>0.013000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10:40:00nan 2015-06-11 nan nan nan</th>\n",
              "      <td>10:40:00nan 2015-06-11 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>240000.0</td>\n",
              "      <td>0.007000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10:00:00nan 2015-07-09 nan nan nan</th>\n",
              "      <td>10:00:00nan 2015-07-09 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>273000.0</td>\n",
              "      <td>0.009000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14:45:00nan 2015-07-30 nan nan nan</th>\n",
              "      <td>14:45:00nan 2015-07-30 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>242000.0</td>\n",
              "      <td>0.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12:15:00nan 2015-11-03 nan nan nan</th>\n",
              "      <td>12:15:00nan 2015-11-03 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>223000.0</td>\n",
              "      <td>0.026000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11:45:00nan 2016-03-01 nan nan nan</th>\n",
              "      <td>11:45:00nan 2016-03-01 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>235000.0</td>\n",
              "      <td>0.040000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11:46:00nan 2016-03-01 nan nan nan</th>\n",
              "      <td>11:46:00nan 2016-03-01 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>235000.0</td>\n",
              "      <td>0.040000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12:30:00nan 2016-05-03 nan nan nan</th>\n",
              "      <td>12:30:00nan 2016-05-03 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>267000.0</td>\n",
              "      <td>0.009000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16:30:00nan 2016-06-07 nan nan nan</th>\n",
              "      <td>16:30:00nan 2016-06-07 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>273000.0</td>\n",
              "      <td>0.013000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12:30:00nan 2016-08-02 nan nan nan</th>\n",
              "      <td>12:30:00nan 2016-08-02 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>246000.0</td>\n",
              "      <td>0.011000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14:00:00nan 2016-09-07 nan nan nan</th>\n",
              "      <td>14:00:00nan 2016-09-07 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>260000.0</td>\n",
              "      <td>0.012000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13:00:00nan 2016-10-05 nan nan nan</th>\n",
              "      <td>13:00:00nan 2016-10-05 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>231000.0</td>\n",
              "      <td>0.011000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12:30:00nan 2016-11-03 nan nan nan</th>\n",
              "      <td>12:30:00nan 2016-11-03 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>217000.0</td>\n",
              "      <td>0.017000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13:30:00nan 2017-02-08 nan nan nan</th>\n",
              "      <td>13:30:00nan 2017-02-08 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>221000.0</td>\n",
              "      <td>0.037000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13:40:00nan 2017-03-06 nan nan nan</th>\n",
              "      <td>13:40:00nan 2017-03-06 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>246000.0</td>\n",
              "      <td>0.022000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15:30:00nan 2017-04-05 nan nan nan</th>\n",
              "      <td>15:30:00nan 2017-04-05 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>276000.0</td>\n",
              "      <td>0.028000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12:15:00nan 2017-07-12 nan nan nan</th>\n",
              "      <td>12:15:00nan 2017-07-12 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>285000.0</td>\n",
              "      <td>0.014000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12:50:00nan 2017-08-09 nan nan nan</th>\n",
              "      <td>12:50:00nan 2017-08-09 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>285000.0</td>\n",
              "      <td>0.012000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11:35:00nan 2017-09-07 nan nan nan</th>\n",
              "      <td>11:35:00nan 2017-09-07 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>255000.0</td>\n",
              "      <td>0.014000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10:00:00nan 2017-10-04 nan nan nan</th>\n",
              "      <td>10:00:00nan 2017-10-04 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>253000.0</td>\n",
              "      <td>0.015000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11:00:00nan 2017-11-16 nan nan nan</th>\n",
              "      <td>11:00:00nan 2017-11-16 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>254000.0</td>\n",
              "      <td>0.017000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11:15:00nan 2017-12-06 nan nan nan</th>\n",
              "      <td>11:15:00nan 2017-12-06 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>283000.0</td>\n",
              "      <td>0.077000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13:00:00nan 2018-01-10 nan nan nan</th>\n",
              "      <td>13:00:00nan 2018-01-10 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>242000.0</td>\n",
              "      <td>0.020000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12:00:00nan 2018-03-07 nan nan nan</th>\n",
              "      <td>12:00:00nan 2018-03-07 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>254000.0</td>\n",
              "      <td>0.017000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16:30:00nan 2018-04-04 nan nan nan</th>\n",
              "      <td>16:30:00nan 2018-04-04 nan nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>341000.0</td>\n",
              "      <td>0.025000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>08:20:0007:20:59 2011-11-22 2011-11-29 nan nan</th>\n",
              "      <td>08:20:0007:20:59 2011-11-22 2011-11-29 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>5310.0</td>\n",
              "      <td>0.257000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>08:45:0007:45:59 2011-11-29 2011-12-06 nan nan</th>\n",
              "      <td>08:45:0007:45:59 2011-11-29 2011-12-06 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>3950.0</td>\n",
              "      <td>0.015000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>08:35:0007:35:59 2011-12-06 2011-12-13 nan nan</th>\n",
              "      <td>08:35:0007:35:59 2011-12-06 2011-12-13 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>3960.0</td>\n",
              "      <td>0.023000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09:30:0008:30:59 2011-12-13 2011-12-20 nan nan</th>\n",
              "      <td>09:30:0008:30:59 2011-12-13 2011-12-20 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>3060.0</td>\n",
              "      <td>0.032000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13:40:0012:40:59 2011-12-20 2011-12-27 nan nan</th>\n",
              "      <td>13:40:0012:40:59 2011-12-20 2011-12-27 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>4690.0</td>\n",
              "      <td>0.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09:10:0008:10:59 2011-12-27 2012-01-03 nan nan</th>\n",
              "      <td>09:10:0008:10:59 2011-12-27 2012-01-03 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>4570.0</td>\n",
              "      <td>0.025000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09:30:0008:30:59 2012-01-03 2012-01-10 nan nan</th>\n",
              "      <td>09:30:0008:30:59 2012-01-03 2012-01-10 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>3270.0</td>\n",
              "      <td>0.013000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09:15:0008:15:59 2012-01-10 2012-01-17 nan nan</th>\n",
              "      <td>09:15:0008:15:59 2012-01-10 2012-01-17 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>3430.0</td>\n",
              "      <td>0.029000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>08:55:0007:55:59 2012-01-17 2012-01-24 nan nan</th>\n",
              "      <td>08:55:0007:55:59 2012-01-17 2012-01-24 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>5630.0</td>\n",
              "      <td>0.038000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>08:57:0007:57:59 2012-01-24 2012-01-31 nan nan</th>\n",
              "      <td>08:57:0007:57:59 2012-01-24 2012-01-31 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>6360.0</td>\n",
              "      <td>0.037000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>08:59:0007:59:59 2012-01-31 2012-02-07 nan nan</th>\n",
              "      <td>08:59:0007:59:59 2012-01-31 2012-02-07 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>6010.0</td>\n",
              "      <td>0.028000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09:10:0008:10:59 2012-02-07 2012-02-14 nan nan</th>\n",
              "      <td>09:10:0008:10:59 2012-02-07 2012-02-14 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>2600.0</td>\n",
              "      <td>0.020000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09:00:0008:00:59 2012-02-14 2012-02-21 nan nan</th>\n",
              "      <td>09:00:0008:00:59 2012-02-14 2012-02-21 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>2300.0</td>\n",
              "      <td>0.324000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09:15:0008:15:59 2012-02-21 2012-02-28 nan nan</th>\n",
              "      <td>09:15:0008:15:59 2012-02-21 2012-02-28 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>2940.0</td>\n",
              "      <td>0.029000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>08:57:0007:57:59 2012-02-28 2012-03-06 nan nan</th>\n",
              "      <td>08:57:0007:57:59 2012-02-28 2012-03-06 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>4120.0</td>\n",
              "      <td>0.049000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10:20:0009:20:59 2012-03-06 2012-03-13 nan nan</th>\n",
              "      <td>10:20:0009:20:59 2012-03-06 2012-03-13 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>4120.0</td>\n",
              "      <td>0.305000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09:28:0008:28:59 2012-03-13 2012-03-20 nan nan</th>\n",
              "      <td>09:28:0008:28:59 2012-03-13 2012-03-20 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>3040.0</td>\n",
              "      <td>0.013000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09:30:0008:30:59 2012-03-20 2012-03-27 nan nan</th>\n",
              "      <td>09:30:0008:30:59 2012-03-20 2012-03-27 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>3120.0</td>\n",
              "      <td>0.036000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09:45:0008:45:59 2012-03-27 2012-04-03 nan nan</th>\n",
              "      <td>09:45:0008:45:59 2012-03-27 2012-04-03 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>2230.0</td>\n",
              "      <td>0.103000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>08:30:0007:30:59 2012-04-03 2012-04-10 nan nan</th>\n",
              "      <td>08:30:0007:30:59 2012-04-03 2012-04-10 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>1870.0</td>\n",
              "      <td>0.031000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10:55:0009:55:59 2012-04-17 2012-04-24 nan nan</th>\n",
              "      <td>10:55:0009:55:59 2012-04-17 2012-04-24 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>1580.0</td>\n",
              "      <td>0.013000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09:02:0008:02:59 2012-04-24 2012-05-01 nan nan</th>\n",
              "      <td>09:02:0008:02:59 2012-04-24 2012-05-01 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>6540.0</td>\n",
              "      <td>0.054000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09:40:0008:40:59 2012-05-01 2012-05-08 nan nan</th>\n",
              "      <td>09:40:0008:40:59 2012-05-01 2012-05-08 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>4880.0</td>\n",
              "      <td>0.132000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09:30:0008:30:59 2012-05-08 2012-05-15 nan nan</th>\n",
              "      <td>09:30:0008:30:59 2012-05-08 2012-05-15 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>3550.0</td>\n",
              "      <td>0.069000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11:40:0006:39:59 2012-05-22 2012-05-29 nan nan</th>\n",
              "      <td>11:40:0006:39:59 2012-05-22 2012-05-29 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>1630.0</td>\n",
              "      <td>0.126000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09:05:0008:05:59 2012-05-29 2012-06-05 nan nan</th>\n",
              "      <td>09:05:0008:05:59 2012-05-29 2012-06-05 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>1740.0</td>\n",
              "      <td>0.061000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09:40:0008:40:59 2012-06-12 2012-06-19 nan nan</th>\n",
              "      <td>09:40:0008:40:59 2012-06-12 2012-06-19 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>2230.0</td>\n",
              "      <td>0.067000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>08:45:0007:45:59 2012-06-19 2012-06-26 nan nan</th>\n",
              "      <td>08:45:0007:45:59 2012-06-19 2012-06-26 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>0.088000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09:00:0008:00:59 2012-06-26 2012-07-03 nan nan</th>\n",
              "      <td>09:00:0008:00:59 2012-06-26 2012-07-03 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>641.0</td>\n",
              "      <td>0.045000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10:30:0009:30:59 2012-07-03 2012-07-10 nan nan</th>\n",
              "      <td>10:30:0009:30:59 2012-07-03 2012-07-10 nan nan</td>\n",
              "      <td>nannan</td>\n",
              "      <td>539.0</td>\n",
              "      <td>0.094000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17219 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                             sampling  ...      conc\n",
              "sampling                                                                                               ...          \n",
              "08:00:00nan 1987-04-15 nan 43.0745076 -77.436104     08:00:00nan 1987-04-15 nan 43.0745076 -77.436104  ...  0.019892\n",
              "08:00:00nan 1987-04-28 nan 43.090618400000004 -...  08:00:00nan 1987-04-28 nan 43.090618400000004 ...  ...  0.010000\n",
              "12:00:00nan 1988-03-22 nan 43.135062899999994 -...  12:00:00nan 1988-03-22 nan 43.135062899999994 ...  ...  0.030001\n",
              "12:45:00nan 1988-04-06 nan 43.147285 -77.5124973     12:45:00nan 1988-04-06 nan 43.147285 -77.5124973  ...  0.000000\n",
              "11:45:00nan 1988-05-03 nan 43.1761737 -77.52666...  11:45:00nan 1988-05-03 nan 43.1761737 -77.5266...  ...  0.000000\n",
              "14:30:00nan 2015-04-08 nan nan nan                                 14:30:00nan 2015-04-08 nan nan nan  ...  0.013000\n",
              "10:40:00nan 2015-06-11 nan nan nan                                 10:40:00nan 2015-06-11 nan nan nan  ...  0.007000\n",
              "10:00:00nan 2015-07-09 nan nan nan                                 10:00:00nan 2015-07-09 nan nan nan  ...  0.009000\n",
              "14:45:00nan 2015-07-30 nan nan nan                                 14:45:00nan 2015-07-30 nan nan nan  ...  0.010000\n",
              "12:15:00nan 2015-11-03 nan nan nan                                 12:15:00nan 2015-11-03 nan nan nan  ...  0.026000\n",
              "11:45:00nan 2016-03-01 nan nan nan                                 11:45:00nan 2016-03-01 nan nan nan  ...  0.040000\n",
              "11:46:00nan 2016-03-01 nan nan nan                                 11:46:00nan 2016-03-01 nan nan nan  ...  0.040000\n",
              "12:30:00nan 2016-05-03 nan nan nan                                 12:30:00nan 2016-05-03 nan nan nan  ...  0.009000\n",
              "16:30:00nan 2016-06-07 nan nan nan                                 16:30:00nan 2016-06-07 nan nan nan  ...  0.013000\n",
              "12:30:00nan 2016-08-02 nan nan nan                                 12:30:00nan 2016-08-02 nan nan nan  ...  0.011000\n",
              "14:00:00nan 2016-09-07 nan nan nan                                 14:00:00nan 2016-09-07 nan nan nan  ...  0.012000\n",
              "13:00:00nan 2016-10-05 nan nan nan                                 13:00:00nan 2016-10-05 nan nan nan  ...  0.011000\n",
              "12:30:00nan 2016-11-03 nan nan nan                                 12:30:00nan 2016-11-03 nan nan nan  ...  0.017000\n",
              "13:30:00nan 2017-02-08 nan nan nan                                 13:30:00nan 2017-02-08 nan nan nan  ...  0.037000\n",
              "13:40:00nan 2017-03-06 nan nan nan                                 13:40:00nan 2017-03-06 nan nan nan  ...  0.022000\n",
              "15:30:00nan 2017-04-05 nan nan nan                                 15:30:00nan 2017-04-05 nan nan nan  ...  0.028000\n",
              "12:15:00nan 2017-07-12 nan nan nan                                 12:15:00nan 2017-07-12 nan nan nan  ...  0.014000\n",
              "12:50:00nan 2017-08-09 nan nan nan                                 12:50:00nan 2017-08-09 nan nan nan  ...  0.012000\n",
              "11:35:00nan 2017-09-07 nan nan nan                                 11:35:00nan 2017-09-07 nan nan nan  ...  0.014000\n",
              "10:00:00nan 2017-10-04 nan nan nan                                 10:00:00nan 2017-10-04 nan nan nan  ...  0.015000\n",
              "11:00:00nan 2017-11-16 nan nan nan                                 11:00:00nan 2017-11-16 nan nan nan  ...  0.017000\n",
              "11:15:00nan 2017-12-06 nan nan nan                                 11:15:00nan 2017-12-06 nan nan nan  ...  0.077000\n",
              "13:00:00nan 2018-01-10 nan nan nan                                 13:00:00nan 2018-01-10 nan nan nan  ...  0.020000\n",
              "12:00:00nan 2018-03-07 nan nan nan                                 12:00:00nan 2018-03-07 nan nan nan  ...  0.017000\n",
              "16:30:00nan 2018-04-04 nan nan nan                                 16:30:00nan 2018-04-04 nan nan nan  ...  0.025000\n",
              "...                                                                                               ...  ...       ...\n",
              "08:20:0007:20:59 2011-11-22 2011-11-29 nan nan         08:20:0007:20:59 2011-11-22 2011-11-29 nan nan  ...  0.257000\n",
              "08:45:0007:45:59 2011-11-29 2011-12-06 nan nan         08:45:0007:45:59 2011-11-29 2011-12-06 nan nan  ...  0.015000\n",
              "08:35:0007:35:59 2011-12-06 2011-12-13 nan nan         08:35:0007:35:59 2011-12-06 2011-12-13 nan nan  ...  0.023000\n",
              "09:30:0008:30:59 2011-12-13 2011-12-20 nan nan         09:30:0008:30:59 2011-12-13 2011-12-20 nan nan  ...  0.032000\n",
              "13:40:0012:40:59 2011-12-20 2011-12-27 nan nan         13:40:0012:40:59 2011-12-20 2011-12-27 nan nan  ...  0.050000\n",
              "09:10:0008:10:59 2011-12-27 2012-01-03 nan nan         09:10:0008:10:59 2011-12-27 2012-01-03 nan nan  ...  0.025000\n",
              "09:30:0008:30:59 2012-01-03 2012-01-10 nan nan         09:30:0008:30:59 2012-01-03 2012-01-10 nan nan  ...  0.013000\n",
              "09:15:0008:15:59 2012-01-10 2012-01-17 nan nan         09:15:0008:15:59 2012-01-10 2012-01-17 nan nan  ...  0.029000\n",
              "08:55:0007:55:59 2012-01-17 2012-01-24 nan nan         08:55:0007:55:59 2012-01-17 2012-01-24 nan nan  ...  0.038000\n",
              "08:57:0007:57:59 2012-01-24 2012-01-31 nan nan         08:57:0007:57:59 2012-01-24 2012-01-31 nan nan  ...  0.037000\n",
              "08:59:0007:59:59 2012-01-31 2012-02-07 nan nan         08:59:0007:59:59 2012-01-31 2012-02-07 nan nan  ...  0.028000\n",
              "09:10:0008:10:59 2012-02-07 2012-02-14 nan nan         09:10:0008:10:59 2012-02-07 2012-02-14 nan nan  ...  0.020000\n",
              "09:00:0008:00:59 2012-02-14 2012-02-21 nan nan         09:00:0008:00:59 2012-02-14 2012-02-21 nan nan  ...  0.324000\n",
              "09:15:0008:15:59 2012-02-21 2012-02-28 nan nan         09:15:0008:15:59 2012-02-21 2012-02-28 nan nan  ...  0.029000\n",
              "08:57:0007:57:59 2012-02-28 2012-03-06 nan nan         08:57:0007:57:59 2012-02-28 2012-03-06 nan nan  ...  0.049000\n",
              "10:20:0009:20:59 2012-03-06 2012-03-13 nan nan         10:20:0009:20:59 2012-03-06 2012-03-13 nan nan  ...  0.305000\n",
              "09:28:0008:28:59 2012-03-13 2012-03-20 nan nan         09:28:0008:28:59 2012-03-13 2012-03-20 nan nan  ...  0.013000\n",
              "09:30:0008:30:59 2012-03-20 2012-03-27 nan nan         09:30:0008:30:59 2012-03-20 2012-03-27 nan nan  ...  0.036000\n",
              "09:45:0008:45:59 2012-03-27 2012-04-03 nan nan         09:45:0008:45:59 2012-03-27 2012-04-03 nan nan  ...  0.103000\n",
              "08:30:0007:30:59 2012-04-03 2012-04-10 nan nan         08:30:0007:30:59 2012-04-03 2012-04-10 nan nan  ...  0.031000\n",
              "10:55:0009:55:59 2012-04-17 2012-04-24 nan nan         10:55:0009:55:59 2012-04-17 2012-04-24 nan nan  ...  0.013000\n",
              "09:02:0008:02:59 2012-04-24 2012-05-01 nan nan         09:02:0008:02:59 2012-04-24 2012-05-01 nan nan  ...  0.054000\n",
              "09:40:0008:40:59 2012-05-01 2012-05-08 nan nan         09:40:0008:40:59 2012-05-01 2012-05-08 nan nan  ...  0.132000\n",
              "09:30:0008:30:59 2012-05-08 2012-05-15 nan nan         09:30:0008:30:59 2012-05-08 2012-05-15 nan nan  ...  0.069000\n",
              "11:40:0006:39:59 2012-05-22 2012-05-29 nan nan         11:40:0006:39:59 2012-05-22 2012-05-29 nan nan  ...  0.126000\n",
              "09:05:0008:05:59 2012-05-29 2012-06-05 nan nan         09:05:0008:05:59 2012-05-29 2012-06-05 nan nan  ...  0.061000\n",
              "09:40:0008:40:59 2012-06-12 2012-06-19 nan nan         09:40:0008:40:59 2012-06-12 2012-06-19 nan nan  ...  0.067000\n",
              "08:45:0007:45:59 2012-06-19 2012-06-26 nan nan         08:45:0007:45:59 2012-06-19 2012-06-26 nan nan  ...  0.088000\n",
              "09:00:0008:00:59 2012-06-26 2012-07-03 nan nan         09:00:0008:00:59 2012-06-26 2012-07-03 nan nan  ...  0.045000\n",
              "10:30:0009:30:59 2012-07-03 2012-07-10 nan nan         10:30:0009:30:59 2012-07-03 2012-07-10 nan nan  ...  0.094000\n",
              "\n",
              "[17219 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuBkoVLryzqb",
        "colab_type": "text"
      },
      "source": [
        "Now we need flow data for places without conc. data.  Doesn't seem to be in the WQ portal, not strictly speaking a WQ parameter (well, it's Water Quantity, not Water Quality).\n",
        "\n",
        "Ran //waterservices.usgs.gov/nwis/site/?format=rdb&bBox=-80.040200,43.064600,-75.969700,44.355000&seriesCatalogOutput=true&siteType=ST&siteStatus=all and created `waterservices.usgs.gov.txt`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ivmBHjHzvOU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "17578e4e-73eb-4c59-8297-6894d8daef4c"
      },
      "source": [
        "d = pd.read_csv(\n",
        "    \"waterservices.usgs.gov.txt\", sep=r'\\t', comment='#', engine='python'\n",
        ")\n",
        "print(len(d))\n",
        "d.set_index(['dec_lat_va', 'dec_long_va'], inplace=True, drop=False)\n",
        "print(len(d.index.unique()))\n",
        "d.groupby(level=[0, 1]).min().to_csv(\"locs2.csv\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28902\n",
            "286\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}